model_list:
  # ── rainymodel/auto ── routes FREE (HF/ollamafreeapi) → INTERNAL (Ollama) → PREMIUM (OpenRouter) ──
  - model_name: rainymodel/auto
    litellm_params:
      model: huggingface/Qwen/Qwen2.5-72B-Instruct
      api_base: https://router.huggingface.co/v1
      api_key: ${HF_TOKEN}
      timeout: 60
    model_info:
      description: "Auto routing - HF Router (free credits)"

  - model_name: rainymodel/auto
    litellm_params:
      model: openai/qwen2.5:latest
      api_base: ${OLLAMAFREE_API_BASE:-https://ollamafreeapi.orcest.ai}/v1
      api_key: ${OLLAMAFREE_API_KEY:-sk-free}
      timeout: 60
    model_info:
      description: "Auto routing - ollamafreeapi (free distributed Ollama)"

  - model_name: rainymodel/auto
    litellm_params:
      model: openai/qwen2.5:14b
      api_base: ${OLLAMA_PRIMARY_URL:-http://164.92.147.36:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Auto routing - primary Ollama 16GB (qwen2.5:14b)"

  - model_name: rainymodel/auto
    litellm_params:
      model: openai/qwen2.5:7b
      api_base: ${OLLAMA_SECONDARY_URL:-http://178.128.196.3:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Auto routing - secondary Ollama 8GB (qwen2.5:7b support)"

  - model_name: rainymodel/auto
    litellm_params:
      model: openrouter/qwen/qwen-2.5-72b-instruct
      api_key: ${OPENROUTER_API_KEY}
      timeout: 90
    model_info:
      description: "Auto routing - OpenRouter (premium fallback)"

  # ── rainymodel/chat ── general/persian chat ──
  - model_name: rainymodel/chat
    litellm_params:
      model: huggingface/Qwen/Qwen2.5-72B-Instruct
      api_base: https://router.huggingface.co/v1
      api_key: ${HF_TOKEN}
      timeout: 60
    model_info:
      description: "Chat - HF Router"

  - model_name: rainymodel/chat
    litellm_params:
      model: openai/qwen2.5:latest
      api_base: ${OLLAMAFREE_API_BASE:-https://ollamafreeapi.orcest.ai}/v1
      api_key: ${OLLAMAFREE_API_KEY:-sk-free}
      timeout: 60
    model_info:
      description: "Chat - ollamafreeapi (free distributed Ollama)"

  - model_name: rainymodel/chat
    litellm_params:
      model: openai/qwen2.5:14b
      api_base: ${OLLAMA_PRIMARY_URL:-http://164.92.147.36:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Chat - primary Ollama 16GB (qwen2.5:14b)"

  - model_name: rainymodel/chat
    litellm_params:
      model: openai/qwen2.5:7b
      api_base: ${OLLAMA_SECONDARY_URL:-http://178.128.196.3:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Chat - secondary Ollama 8GB (qwen2.5:7b support)"

  - model_name: rainymodel/chat
    litellm_params:
      model: openrouter/qwen/qwen-2.5-72b-instruct
      api_key: ${OPENROUTER_API_KEY}
      timeout: 90
    model_info:
      description: "Chat - OpenRouter fallback"

  # ── rainymodel/code ── coding tasks ──
  - model_name: rainymodel/code
    litellm_params:
      model: huggingface/Qwen/Qwen2.5-Coder-32B-Instruct
      api_base: https://router.huggingface.co/v1
      api_key: ${HF_TOKEN}
      timeout: 60
    model_info:
      description: "Code - HF Router (Qwen Coder)"

  - model_name: rainymodel/code
    litellm_params:
      model: openai/qwen2.5-coder:latest
      api_base: ${OLLAMAFREE_API_BASE:-https://ollamafreeapi.orcest.ai}/v1
      api_key: ${OLLAMAFREE_API_KEY:-sk-free}
      timeout: 60
    model_info:
      description: "Code - ollamafreeapi (free distributed Ollama)"

  - model_name: rainymodel/code
    litellm_params:
      model: openai/qwen2.5-coder:7b
      api_base: ${OLLAMA_PRIMARY_URL:-http://164.92.147.36:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Code - primary Ollama 16GB (Qwen Coder 7B)"

  - model_name: rainymodel/code
    litellm_params:
      model: openai/qwen2.5-coder:7b
      api_base: ${OLLAMA_SECONDARY_URL:-http://178.128.196.3:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Code - secondary Ollama 8GB (Qwen Coder 7B support)"

  - model_name: rainymodel/code
    litellm_params:
      model: openrouter/qwen/qwen-2.5-coder-32b-instruct
      api_key: ${OPENROUTER_API_KEY}
      timeout: 90
    model_info:
      description: "Code - OpenRouter fallback"

  # ── rainymodel/agent ── agent/complex tasks (prefer premium) ──
  - model_name: rainymodel/agent
    litellm_params:
      model: openrouter/anthropic/claude-sonnet-4
      api_key: ${OPENROUTER_API_KEY}
      timeout: 120
    model_info:
      description: "Agent - OpenRouter premium (Claude)"

  - model_name: rainymodel/agent
    litellm_params:
      model: huggingface/Qwen/Qwen2.5-72B-Instruct
      api_base: https://router.huggingface.co/v1
      api_key: ${HF_TOKEN}
      timeout: 90
    model_info:
      description: "Agent - HF Router fallback"

  - model_name: rainymodel/agent
    litellm_params:
      model: openai/qwen2.5:latest
      api_base: ${OLLAMAFREE_API_BASE:-https://ollamafreeapi.orcest.ai}/v1
      api_key: ${OLLAMAFREE_API_KEY:-sk-free}
      timeout: 60
    model_info:
      description: "Agent - ollamafreeapi fallback"

  - model_name: rainymodel/agent
    litellm_params:
      model: openai/qwen2.5:14b
      api_base: ${OLLAMA_PRIMARY_URL:-http://164.92.147.36:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Agent - primary Ollama 16GB fallback"

  - model_name: rainymodel/agent
    litellm_params:
      model: openai/qwen2.5:7b
      api_base: ${OLLAMA_SECONDARY_URL:-http://178.128.196.3:11434}/v1
      api_key: ${OLLAMA_API_KEY:-ollama}
      timeout: 120
    model_info:
      description: "Agent - secondary Ollama 8GB fallback"

router_settings:
  routing_strategy: "simple-shuffle"
  num_retries: 3
  timeout: 120
  retry_after: 5
  allowed_fails: 2
  cooldown_time: 60

general_settings:
  master_key: ${RAINYMODEL_MASTER_KEY}
  alerting: null
  drop_params: true
